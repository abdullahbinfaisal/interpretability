{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ae5fa7",
   "metadata": {},
   "source": [
    "#### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd86d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data_handlers import Load_ImageNet100\n",
    "from overcomplete.models import DinoV2, ViT, ResNet\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from overcomplete.sae import TopKSAE, train_sae\n",
    "from overcomplete.visualization import (overlay_top_heatmaps, evidence_top_images, zoom_top_images, contour_top_image)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "from universal_trainer import train_usae\n",
    "from activation_generator import Load_activation_dataloader\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a7c042",
   "metadata": {},
   "source": [
    "### Train a USAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998439e",
   "metadata": {},
   "source": [
    "Define Models and Generate Their Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68d84da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\sproj_ha/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "C:\\Users\\sproj_ha/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "C:\\Users\\sproj_ha/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "C:\\Users\\sproj_ha/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "c:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"DinoV2\": DinoV2(device=\"cuda\"),\n",
    "    \"ViT\": ViT(device=\"cuda\")\n",
    "}\n",
    "\n",
    "activation_dir = \"activations/ImageNet100_Dino_ViT\"\n",
    "image_loader = Load_ImageNet100(transform=None, batch_size=256, shuffle=True)\n",
    "\n",
    "activations_dataloader = Load_activation_dataloader(\n",
    "    models=models,\n",
    "    image_dataloader=image_loader, \n",
    "    save_dir=activation_dir, \n",
    "    generate=False,  \n",
    "    rearrange_string='n t d -> (n t) d'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35fc11e",
   "metadata": {},
   "source": [
    "SAE Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cae4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = 1024\n",
    "epochs = 20\n",
    "lr=5e-4\n",
    "sample = next(iter(activations_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c2eb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 65536, 384])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['activations_DinoV2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "698beefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/127 [00:00<?, ?it/s]c:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:610: UserWarning: Using a target size (torch.Size([50176, 768])) that is different to the input size (torch.Size([65536, 768])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch 1/20:   0%|          | 0/127 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (65536) must match the size of tensor b (50176) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      6\u001b[39m   optimizers[key] = torch.optim.Adam(SAEs[key].parameters(), lr=lr)\n\u001b[32m      8\u001b[39m criterion = nn.MSELoss()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtrain_usae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m           \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSAEs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m           \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactivations_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m           \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m           \u001b[49m\u001b[43mnb_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m           \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m           \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\Desktop\\vision_interp\\universal_trainer.py:79\u001b[39m, in \u001b[36mtrain_usae\u001b[39m\u001b[34m(names, models, dataloader, criterion, optimizers, schedulers, nb_epochs, clip_grad, monitoring, device)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n, m \u001b[38;5;129;01min\u001b[39;00m models.items():\n\u001b[32m     78\u001b[39m     x_hat = m.decode(z)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     total_loss += \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mactivations_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Backward + Optimize\u001b[39;00m\n\u001b[32m     82\u001b[39m total_loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:610\u001b[39m, in \u001b[36mMSELoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\nn\\functional.py:3884\u001b[39m, in \u001b[36mmse_loss\u001b[39m\u001b[34m(input, target, size_average, reduce, reduction, weight)\u001b[39m\n\u001b[32m   3881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3882\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3884\u001b[39m expanded_input, expanded_target = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3887\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m weight.size() != \u001b[38;5;28minput\u001b[39m.size():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\functional.py:77\u001b[39m, in \u001b[36mbroadcast_tensors\u001b[39m\u001b[34m(*tensors)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, *tensors)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (65536) must match the size of tensor b (50176) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "SAEs = {}\n",
    "optimizers = {}\n",
    "\n",
    "for key, model in models.items():\n",
    "  SAEs[key] = TopKSAE(sample[f\"activations_{key}\"].shape[-1], nb_concepts=concepts, top_k=3, device='cuda')\n",
    "  optimizers[key] = torch.optim.Adam(SAEs[key].parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_usae(names=list(models.keys()),\n",
    "           models=SAEs,\n",
    "           dataloader=activations_dataloader,\n",
    "           criterion=criterion,\n",
    "           nb_epochs=epochs,\n",
    "           optimizers=optimizers,\n",
    "           device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f35e63e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Code Shape:  torch.Size([392000, 384])\n",
      "Rearranged Code Shape:  torch.Size([2000, 14, 14, 384])\n"
     ]
    }
   ],
   "source": [
    "# now the funny part, we have access to 4 functions that allow us to inspect the concepts,\n",
    "# let use them to understand a bit more the top 3 concepts !\n",
    "\n",
    "sae = sae.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  pre_codes, codes = sae.encode(Activations)\n",
    "\n",
    "\n",
    "print(\"Raw Code Shape: \", codes.shape)\n",
    "codes = rearrange(codes, '(n w h) d -> n w h d', w=14, h=14)\n",
    "print(\"Rearranged Code Shape: \", codes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "806b60de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-108 Concepts by L1 Norm\n",
      "Concept 234\n",
      "Concept 150\n",
      "Concept 59\n",
      "Concept 110\n",
      "Concept 127\n",
      "Concept 365\n",
      "Concept 13\n",
      "Concept 78\n",
      "Concept 254\n",
      "Concept 8\n",
      "Concept 354\n",
      "Concept 275\n",
      "Concept 45\n",
      "Concept 151\n",
      "Concept 293\n",
      "Concept 158\n",
      "Concept 20\n",
      "Concept 195\n",
      "Concept 170\n",
      "Concept 89\n",
      "Concept 72\n",
      "Concept 217\n",
      "Concept 277\n",
      "Concept 373\n",
      "Concept 209\n",
      "Concept 192\n",
      "Concept 169\n",
      "Concept 79\n",
      "Concept 153\n",
      "Concept 270\n",
      "Concept 219\n",
      "Concept 320\n",
      "Concept 65\n",
      "Concept 19\n",
      "Concept 290\n",
      "Concept 274\n",
      "Concept 172\n",
      "Concept 5\n",
      "Concept 96\n",
      "Concept 210\n",
      "Concept 244\n",
      "Concept 358\n",
      "Concept 379\n",
      "Concept 301\n",
      "Concept 36\n",
      "Concept 61\n",
      "Concept 164\n",
      "Concept 50\n",
      "Concept 104\n",
      "Concept 376\n",
      "Concept 356\n",
      "Concept 179\n",
      "Concept 364\n",
      "Concept 327\n",
      "Concept 68\n",
      "Concept 264\n",
      "Concept 93\n",
      "Concept 49\n",
      "Concept 207\n",
      "Concept 242\n",
      "Concept 12\n",
      "Concept 310\n",
      "Concept 269\n",
      "Concept 4\n",
      "Concept 148\n",
      "Concept 218\n",
      "Concept 157\n",
      "Concept 258\n",
      "Concept 268\n",
      "Concept 241\n",
      "Concept 40\n",
      "Concept 294\n",
      "Concept 198\n",
      "Concept 44\n",
      "Concept 307\n",
      "Concept 149\n",
      "Concept 42\n",
      "Concept 58\n",
      "Concept 90\n",
      "Concept 299\n",
      "Concept 176\n",
      "Concept 288\n",
      "Concept 206\n",
      "Concept 278\n",
      "Concept 138\n",
      "Concept 248\n",
      "Concept 345\n",
      "Concept 147\n",
      "Concept 116\n",
      "Concept 201\n",
      "Concept 253\n",
      "Concept 355\n",
      "Concept 135\n",
      "Concept 92\n",
      "Concept 63\n",
      "Concept 223\n",
      "Concept 141\n",
      "Concept 259\n",
      "Concept 160\n",
      "Concept 221\n",
      "Concept 37\n",
      "Concept 366\n",
      "Concept 296\n",
      "Concept 232\n",
      "Concept 0\n",
      "Concept 1\n",
      "Concept 2\n",
      "Concept 3\n"
     ]
    }
   ],
   "source": [
    "# Compute per-concept L1 norm across all spatial positions and batch\n",
    "codes_flat = codes.abs().sum(dim=(1, 2))        # (32, D)\n",
    "concept_strength = codes_flat.sum(dim=0)        # (D,)\n",
    "\n",
    "topk = int((1 - logs['dead_features'][-1]) * concepts)\n",
    "top_concepts = torch.argsort(concept_strength, descending=True)[:topk].to(device)\n",
    "\n",
    "print(f\"Top-{topk} Concepts by L1 Norm\")\n",
    "\n",
    "# first, lets use the simple overlay to get a broad sense of what's going on\n",
    "for concept_id in top_concepts:\n",
    "  print('Concept', concept_id.item())\n",
    "  overlay_top_heatmaps(image, codes, concept_id=concept_id.item())\n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "  filename = f\"concept_{concept_id.item()}.png\"\n",
    "  filepath = os.path.join(save_dir, filename)\n",
    "  plt.savefig(filepath, bbox_inches='tight', dpi=300)\n",
    "  plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79650a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
