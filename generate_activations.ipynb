{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7867570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data_handlers import Load_ImageNet100\n",
    "from overcomplete.models import DinoV2, ViT, ResNet\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from overcomplete.sae import TopKSAE, train_sae\n",
    "from overcomplete.visualization import (overlay_top_heatmaps, evidence_top_images, zoom_top_images, contour_top_image)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99f4134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\sproj_ha/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "C:\\Users\\sproj_ha/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "C:\\Users\\sproj_ha/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "C:\\Users\\sproj_ha/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "model = DinoV2(device=\"cuda\")\n",
    "save_dir = \"activations/DinoV2_ImageNet100\"\n",
    "dataloader = Load_ImageNet100(transform=model.preprocess, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8e41bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 0 with 256 samples.\n",
      "Saved batch 1 with 256 samples.\n",
      "Saved batch 2 with 256 samples.\n",
      "Saved batch 3 with 256 samples.\n",
      "Saved batch 4 with 256 samples.\n",
      "Saved batch 5 with 256 samples.\n",
      "Saved batch 6 with 256 samples.\n",
      "Saved batch 7 with 256 samples.\n",
      "Saved batch 8 with 256 samples.\n",
      "Saved batch 9 with 256 samples.\n",
      "Saved batch 10 with 256 samples.\n",
      "Saved batch 11 with 256 samples.\n",
      "Saved batch 12 with 256 samples.\n",
      "Saved batch 13 with 256 samples.\n",
      "Saved batch 14 with 256 samples.\n",
      "Saved batch 15 with 256 samples.\n",
      "Saved batch 16 with 256 samples.\n",
      "Saved batch 17 with 256 samples.\n",
      "Saved batch 18 with 256 samples.\n",
      "Saved batch 19 with 256 samples.\n",
      "Saved batch 20 with 256 samples.\n",
      "Saved batch 21 with 256 samples.\n",
      "Saved batch 22 with 256 samples.\n",
      "Saved batch 23 with 256 samples.\n",
      "Saved batch 24 with 256 samples.\n",
      "Saved batch 25 with 256 samples.\n",
      "Saved batch 26 with 256 samples.\n",
      "Saved batch 27 with 256 samples.\n",
      "Saved batch 28 with 256 samples.\n",
      "Saved batch 29 with 256 samples.\n",
      "Saved batch 30 with 256 samples.\n",
      "Saved batch 31 with 256 samples.\n",
      "Saved batch 32 with 256 samples.\n",
      "Saved batch 33 with 256 samples.\n",
      "Saved batch 34 with 256 samples.\n",
      "Saved batch 35 with 256 samples.\n",
      "Saved batch 36 with 256 samples.\n",
      "Saved batch 37 with 256 samples.\n",
      "Saved batch 38 with 256 samples.\n",
      "Saved batch 39 with 256 samples.\n",
      "Saved batch 40 with 256 samples.\n",
      "Saved batch 41 with 256 samples.\n",
      "Saved batch 42 with 256 samples.\n",
      "Saved batch 43 with 256 samples.\n",
      "Saved batch 44 with 256 samples.\n",
      "Saved batch 45 with 256 samples.\n",
      "Saved batch 46 with 256 samples.\n",
      "Saved batch 47 with 256 samples.\n",
      "Saved batch 48 with 256 samples.\n",
      "Saved batch 49 with 256 samples.\n",
      "Saved batch 50 with 256 samples.\n",
      "Saved batch 51 with 256 samples.\n",
      "Saved batch 52 with 256 samples.\n",
      "Saved batch 53 with 256 samples.\n",
      "Saved batch 54 with 256 samples.\n",
      "Saved batch 55 with 256 samples.\n",
      "Saved batch 56 with 256 samples.\n",
      "Saved batch 57 with 256 samples.\n",
      "Saved batch 58 with 256 samples.\n",
      "Saved batch 59 with 256 samples.\n",
      "Saved batch 60 with 256 samples.\n",
      "Saved batch 61 with 256 samples.\n",
      "Saved batch 62 with 256 samples.\n",
      "Saved batch 63 with 256 samples.\n",
      "Saved batch 64 with 256 samples.\n",
      "Saved batch 65 with 256 samples.\n",
      "Saved batch 66 with 256 samples.\n",
      "Saved batch 67 with 256 samples.\n",
      "Saved batch 68 with 256 samples.\n",
      "Saved batch 69 with 256 samples.\n",
      "Saved batch 70 with 256 samples.\n",
      "Saved batch 71 with 256 samples.\n",
      "Saved batch 72 with 256 samples.\n",
      "Saved batch 73 with 256 samples.\n",
      "Saved batch 74 with 256 samples.\n",
      "Saved batch 75 with 256 samples.\n",
      "Saved batch 76 with 256 samples.\n",
      "Saved batch 77 with 256 samples.\n",
      "Saved batch 78 with 256 samples.\n",
      "Saved batch 79 with 256 samples.\n",
      "Saved batch 80 with 256 samples.\n",
      "Saved batch 81 with 256 samples.\n",
      "Saved batch 82 with 256 samples.\n",
      "Saved batch 83 with 256 samples.\n",
      "Saved batch 84 with 256 samples.\n",
      "Saved batch 85 with 256 samples.\n",
      "Saved batch 86 with 256 samples.\n",
      "Saved batch 87 with 256 samples.\n",
      "Saved batch 88 with 256 samples.\n",
      "Saved batch 89 with 256 samples.\n",
      "Saved batch 90 with 256 samples.\n",
      "Saved batch 91 with 256 samples.\n",
      "Saved batch 92 with 256 samples.\n",
      "Saved batch 93 with 256 samples.\n",
      "Saved batch 94 with 256 samples.\n",
      "Saved batch 95 with 256 samples.\n",
      "Saved batch 96 with 256 samples.\n",
      "Saved batch 97 with 256 samples.\n",
      "Saved batch 98 with 256 samples.\n",
      "Saved batch 99 with 256 samples.\n",
      "Saved batch 100 with 256 samples.\n",
      "Saved batch 101 with 256 samples.\n",
      "Saved batch 102 with 256 samples.\n",
      "Saved batch 103 with 256 samples.\n",
      "Saved batch 104 with 256 samples.\n",
      "Saved batch 105 with 256 samples.\n",
      "Saved batch 106 with 256 samples.\n",
      "Saved batch 107 with 256 samples.\n",
      "Saved batch 108 with 256 samples.\n",
      "Saved batch 109 with 256 samples.\n",
      "Saved batch 110 with 256 samples.\n",
      "Saved batch 111 with 256 samples.\n",
      "Saved batch 112 with 256 samples.\n",
      "Saved batch 113 with 256 samples.\n",
      "Saved batch 114 with 256 samples.\n",
      "Saved batch 115 with 256 samples.\n",
      "Saved batch 116 with 256 samples.\n",
      "Saved batch 117 with 256 samples.\n",
      "Saved batch 118 with 256 samples.\n",
      "Saved batch 119 with 256 samples.\n",
      "Saved batch 120 with 256 samples.\n",
      "Saved batch 121 with 256 samples.\n",
      "Saved batch 122 with 256 samples.\n",
      "Saved batch 123 with 256 samples.\n",
      "Saved batch 124 with 256 samples.\n",
      "Saved batch 125 with 256 samples.\n",
      "Saved batch 126 with 244 samples.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model.to(device).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, _) in enumerate(dataloader):\n",
    "        images = images.to(device)\n",
    "        activations = model.forward_features(images)\n",
    "\n",
    "        # Move to CPU before saving\n",
    "        batch_data = {\n",
    "            'images': images.cpu(),          # shape: (B, C, H, W)\n",
    "            'activations': activations.cpu() # shape: (B, ...)\n",
    "        }\n",
    "\n",
    "        torch.save(batch_data, os.path.join(save_dir, f\"batch_{i:05d}.pt\"))\n",
    "        print(f\"Saved batch {i} with {images.size(0)} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babde814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
