{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85c93a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from lib.data_handlers import Load_ImageNet100, Load_PACS, Load_ImageNet100Sketch\n",
    "from overcomplete.models import DinoV2, ViT, ResNet, ViT_Large, SigLIP\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from overcomplete.sae import TopKSAE, train_sae\n",
    "from overcomplete.visualization import (overlay_top_heatmaps, evidence_top_images, zoom_top_images, contour_top_image)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "from lib.universal_trainer import train_usae\n",
    "from lib.activation_generator import Load_activation_dataloader\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
    "from lib.eval import evaluate_models\n",
    "from lib.visualizer import visualize_concepts\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce69d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"ViT\": ViT(device=\"cuda\")\n",
    "}\n",
    "\n",
    "activations_dir=\"/activations/ViT_Solo\"\n",
    "\n",
    "image_loader, image_dataset = Load_ImageNet100(transform=None, batch_size=256, shuffle=True, dataset_allow=True)\n",
    "\n",
    "activations_dataloader = Load_activation_dataloader(\n",
    "    models=models,\n",
    "    image_dataloader=image_loader,\n",
    "    max_seq_len=196,\n",
    "    save_dir=activations_dir,\n",
    "    generate=False,\n",
    "    rearrange_string='n t d -> (n t) d'\n",
    ")\n",
    "\n",
    "concepts = 768 * 8\n",
    "epochs = 100\n",
    "lr=3e-4\n",
    "sample = next(iter(activations_dataloader))\n",
    "\n",
    "SAEs = {}\n",
    "optimizers = {}\n",
    "schedulers = {}\n",
    "\n",
    "for key, model in models.items():\n",
    "\n",
    "    SAEs[key] = TopKSAE(\n",
    "        sample[f\"activations_{key}\"].shape[-1],\n",
    "        nb_concepts=concepts,\n",
    "        top_k=16,\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "    optimizers[key] = torch.optim.Adam(SAEs[key].parameters(), lr=lr)\n",
    "\n",
    "    # Set up a Linear + Cosine Scheduler\n",
    "    warmup_scheduler = LinearLR(\n",
    "        optimizers[key], start_factor=1e-6 / 3e-4, end_factor=1.0, total_iters=10\n",
    "    )\n",
    "    cosine_scheduler = CosineAnnealingLR(optimizers[key], T_max=epochs, eta_min=1e-6)\n",
    "    schedulers[key] = SequentialLR(\n",
    "        optimizers[key],\n",
    "        schedulers=[warmup_scheduler, cosine_scheduler],\n",
    "        milestones=[25],\n",
    "    )\n",
    "\n",
    "criterion = nn.L1Loss(reduction=\"mean\")  # change to mean reduction\n",
    "\n",
    "model_path = \"./models/ViT_MLP.pt\"\n",
    "state = torch.load(model_path)\n",
    "\n",
    "for name, sae in SAEs.items():\n",
    "    print(sae.load_state_dict(state[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd848f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = SAEs['ViT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d3f0040",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01movercomplete\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcmaps\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VIRIDIS_ALPHA\n\u001b[32m     10\u001b[39m transform = transforms.ToTensor()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m vit = models[\u001b[33m'\u001b[39m\u001b[33mViT\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     15\u001b[39m CONCEPT = \u001b[32m1001\u001b[39m\n\u001b[32m     20\u001b[39m x = Image.open(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33msproj_ha\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDesktop\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mvision_interp\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdatasets\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mimagenetsketch\u001b[39m\u001b[33m\\\u001b[39m\u001b[33msketch\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mn01484850\u001b[39m\u001b[33m\\\u001b[39m\u001b[33msketch_25.JPEG\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from overcomplete.visualization.plot_utils import (\n",
    "    get_image_dimensions,\n",
    "    interpolate_cv2,\n",
    "    show,\n",
    ")\n",
    "from overcomplete.visualization.cmaps import VIRIDIS_ALPHA\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "vit = models['ViT']\n",
    "\n",
    "\n",
    "\n",
    "CONCEPT = 1001\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = Image.open(r\"C:\\Users\\sproj_ha\\Desktop\\vision_interp\\datasets\\imagenetsketch\\sketch\\n01484850\\sketch_25.JPEG\")\n",
    "#x = Image.open(r\"C:\\Users\\sproj_ha\\Desktop\\vision_interp\\datasets\\imagenet100\\train.X1\\n01484850\\n01484850_22127.JPEG\")\n",
    "x = vit.preprocess(x).unsqueeze(dim=0)\n",
    "\n",
    "\n",
    "\n",
    "y = vit.forward_features(x.to(device))\n",
    "y = rearrange(y, 'n t d -> (n t) d')\n",
    "\n",
    "_, z_sae = sae.encode(y)\n",
    "\n",
    "z = rearrange(z_sae, '(n w h) d -> n w h d', w=14, h=14)\n",
    "\n",
    "\n",
    "print(z.shape)\n",
    "\n",
    "width, height = x.shape[-1], x.shape[-2]\n",
    "heatmap = interpolate_cv2(z[:, :, :, CONCEPT], (width, height))\n",
    "\n",
    "show(x)\n",
    "show(heatmap, cmap=VIRIDIS_ALPHA, alpha=1.0)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27bc5b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 6.3559, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, :, :, 2103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1caef2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[19.9766, 14.3027,  7.7557,  0.0000,  0.0000,  0.0000,  3.6836,\n",
       "          17.3181, 20.1870, 22.0441, 23.2858, 31.1823,  0.0000, 22.2857],\n",
       "         [24.5803, 18.8284,  0.0000, 19.3685,  0.0000, 15.0874, 22.0635,\n",
       "          13.4357, 25.7941, 26.1300, 21.0075, 24.5400, 28.1543, 24.3410],\n",
       "         [30.0213, 12.0903, 18.1600,  7.4773, 13.5518, 16.3262, 21.9222,\n",
       "           0.0000, 26.8441, 29.0237, 31.1096, 29.7123, 29.4751, 17.5995],\n",
       "         [15.7591,  0.0000, 11.4290, 18.0678, 14.1870, 15.5788, 11.9302,\n",
       "           3.7486, 19.5462, 31.5032, 28.4118, 24.2155, 28.7570, 30.3989],\n",
       "         [19.2333, 26.9912, 30.7342, 27.6582, 32.3362,  0.0000, 24.5212,\n",
       "          27.2884, 23.9400, 25.0193, 24.5292, 23.8809, 22.9710, 21.0826],\n",
       "         [28.8186, 27.9392, 29.8642, 29.1240, 28.0282,  2.5779, 25.8641,\n",
       "          21.1394, 19.5301, 19.0142, 16.2736, 18.8964, 23.3597, 29.4259],\n",
       "         [25.0967, 29.2316,  0.0000, 26.3386, 26.7003, 25.3071, 26.7243,\n",
       "          19.8372, 23.6092, 17.9762, 10.4967, 23.6187, 18.0441, 25.7229],\n",
       "         [29.9729,  0.0000, 21.1658, 25.8391, 27.3312, 13.5061, 27.1946,\n",
       "          21.1262, 21.4244, 12.5759, 16.6528, 21.9902, 19.3419, 24.2467],\n",
       "         [23.9517, 20.0809, 17.0831, 19.5501, 15.1677, 24.6214, 25.9476,\n",
       "          20.3276, 24.4138, 15.6981, 24.9139, 19.0867, 17.1859, 22.1878],\n",
       "         [24.5080, 22.8113, 28.9039, 20.7368, 28.6591, 24.2045, 20.4998,\n",
       "          19.4287, 26.2946, 27.3028, 13.2010, 22.7630, 15.2148, 28.0738],\n",
       "         [23.0265, 23.5020, 26.6253, 25.1412, 22.2498, 21.7352, 28.6247,\n",
       "          28.4081, 27.0614, 19.8970, 24.7149, 17.1513, 20.2893, 22.1684],\n",
       "         [30.3917, 23.2388, 28.6355, 18.6224, 24.1595, 28.7908, 26.6530,\n",
       "          31.3642, 30.3194, 28.7280, 25.9677, 28.3979, 22.0329, 23.8569],\n",
       "         [22.2199, 27.2160, 23.6943, 23.1782, 23.8755, 26.4860, 20.7560,\n",
       "          20.1634, 27.4607, 24.6252, 16.8738, 27.4954, 22.7562, 20.9561],\n",
       "         [19.1277, 18.7553, 22.0652, 16.2109, 27.4154, 22.0960, 18.3331,\n",
       "          19.2353, 22.9014, 28.0077, 23.4055, 20.2818, 16.4140, 25.8216]]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, :, :, 4395]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a613f38b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
