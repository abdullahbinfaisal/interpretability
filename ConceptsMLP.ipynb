{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a85c93a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from overcomplete.models import DinoV2, ViT, ResNet, ViT_Large, SigLIP\n",
    "from overcomplete.sae import TopKSAE\n",
    "from overcomplete.visualization.plot_utils import (interpolate_cv2, show)\n",
    "from overcomplete.visualization.cmaps import VIRIDIS_ALPHA\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ce69d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = ViT(device=\"cuda\")\n",
    "\n",
    "\n",
    "# Load SAE\n",
    "sae = TopKSAE(768, nb_concepts=768*8, top_k=16, device=\"cuda\")\n",
    "sae.load_state_dict(torch.load(\"./models/ViT_MLP.pt\")[\"ViT\"])\n",
    "\n",
    "## Define domain paths\n",
    "domain_roots = {\n",
    "    \"inet\": \"./datasets/imagenet100/train.X1\",\n",
    "    \"sketch\": \"./datasets/imagenetsketch/sketch\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aff2a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_class_on_concept(concept, class_idx, model, sae, domain_roots):\n",
    "    transform = transforms.ToTensor()\n",
    "    \n",
    "\n",
    "    for domain, dir in domain_roots.items(): \n",
    "        classes = os.listdir(dir)\n",
    "        class_dir = os.path.join(dir, classes[class_idx])\n",
    "\n",
    "        images = [Image.open(os.path.join(path)) for path in os.listdir(class_dir)]\n",
    "\n",
    "        for img in images:\n",
    "            img = model.preprocess(img).unsqueeze(dim=0)\n",
    "            x = model.forward_features(img.to(device))\n",
    "            x = rearrange(x, 'n t d -> (n t) d')\n",
    "            _, z = sae.encode(x)\n",
    "            z = rearrange(z, '(n w h) d -> n w h d', w=14, h=14)\n",
    "            width, height = img.shape[-1], img.shape[-2]\n",
    "            heatmap = interpolate_cv2(z[:, :, :, concept], (width, height))\n",
    "            show(x)\n",
    "            show(heatmap, cmap=VIRIDIS_ALPHA, alpha=1.0)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297e36b",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_class_on_concept(\n",
    "    concept=606,\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
