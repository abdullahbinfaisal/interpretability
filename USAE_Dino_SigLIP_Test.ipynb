{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ae5fa7",
   "metadata": {},
   "source": [
    "#### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd86d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from lib.data_handlers import Load_ImageNet100, Load_PACS\n",
    "from overcomplete.models import DinoV2, ViT, ResNet, ViT_Large, SigLIP\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from overcomplete.sae import TopKSAE, train_sae\n",
    "from overcomplete.visualization import (overlay_top_heatmaps, evidence_top_images, zoom_top_images, contour_top_image)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "from lib.universal_trainer import train_usae\n",
    "from lib.activation_generator import Load_activation_dataloader\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3417692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a7c042",
   "metadata": {},
   "source": [
    "### Train a USAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998439e",
   "metadata": {},
   "source": [
    "Define Models and Generate Their Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d84da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sproj_ha\\.cache\\huggingface\\hub\\models--timm--vit_base_patch16_siglip_224.v2_webli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Processing Batches:  45%|████▌     | 231/508 [06:48<07:59,  1.73s/it]"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "models = {\n",
    "    \"ViT\": ViT(device=\"cuda\"),\n",
    "    \"SigLIP\": SigLIP(device=\"cuda\")\n",
    "}\n",
    "\n",
    "activation_dir = \"activations/ImageNet100_ViT_SigLIP\"\n",
    "image_loader = Load_ImageNet100(transform=None, batch_size=256, shuffle=True)\n",
    "\n",
    "\n",
    "activations_dataloader = Load_activation_dataloader(\n",
    "    models=models,\n",
    "    image_dataloader=image_loader,\n",
    "    max_seq_len=196,   \n",
    "    save_dir=activation_dir, \n",
    "    generate=True,  \n",
    "    rearrange_string='n t d -> (n t) d'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35fc11e",
   "metadata": {},
   "source": [
    "SAE Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = 768 * 8\n",
    "epochs = 40\n",
    "lr=3e-4\n",
    "sample = next(iter(activations_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698beefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   9%|▉         | 48/508 [00:35<03:56,  1.95it/s, loss=1.39]c:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:198: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Epoch 1/20: 100%|██████████| 508/508 [07:01<00:00,  1.21it/s, loss=1.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1] Loss: 694.6747 | Time: 421.47s | Dead Features: 0.0%\n",
      "ViT Loss: [308.1587703227997]\n",
      "DinoV2 Loss: [386.51594799757004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 508/508 [13:42<00:00,  1.62s/it, loss=1.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 2] Loss: 676.8938 | Time: 822.66s | Dead Features: 71.3%\n",
      "ViT Loss: [308.1587703227997, 293.40135046839714]\n",
      "DinoV2 Loss: [386.51594799757004, 383.49242997169495]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 508/508 [13:30<00:00,  1.60s/it, loss=1.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 3] Loss: 671.6713 | Time: 810.70s | Dead Features: 87.6%\n",
      "ViT Loss: [308.1587703227997, 293.40135046839714, 291.0020546913147]\n",
      "DinoV2 Loss: [386.51594799757004, 383.49242997169495, 380.669264793396]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 508/508 [13:29<00:00,  1.59s/it, loss=1.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 4] Loss: 670.7984 | Time: 809.93s | Dead Features: 90.7%\n",
      "ViT Loss: [308.1587703227997, 293.40135046839714, 291.0020546913147, 290.23292818665504]\n",
      "DinoV2 Loss: [386.51594799757004, 383.49242997169495, 380.669264793396, 380.56543242931366]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 508/508 [13:30<00:00,  1.59s/it, loss=1.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 5] Loss: 671.3460 | Time: 810.23s | Dead Features: 91.5%\n",
      "ViT Loss: [308.1587703227997, 293.40135046839714, 291.0020546913147, 290.23292818665504, 289.9391912519932]\n",
      "DinoV2 Loss: [386.51594799757004, 383.49242997169495, 380.669264793396, 380.56543242931366, 381.40680783987045]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 508/508 [13:28<00:00,  1.59s/it, loss=1.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 6] Loss: 671.7623 | Time: 808.74s | Dead Features: 90.3%\n",
      "ViT Loss: [308.1587703227997, 293.40135046839714, 291.0020546913147, 290.23292818665504, 289.9391912519932, 289.6635777056217]\n",
      "DinoV2 Loss: [386.51594799757004, 383.49242997169495, 380.669264793396, 380.56543242931366, 381.40680783987045, 382.09873074293137]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20:  36%|███▋      | 185/508 [04:53<07:47,  1.45s/it, loss=1.4] "
     ]
    }
   ],
   "source": [
    "SAEs = {}\n",
    "optimizers = {}\n",
    "schedulers = {}\n",
    "\n",
    "for key, model in models.items():\n",
    "  \n",
    "  SAEs[key] = TopKSAE(sample[f\"activations_{key}\"].shape[-1], nb_concepts=concepts, top_k=64, device='cuda')\n",
    "  optimizers[key] = torch.optim.Adam(SAEs[key].parameters(), lr=lr)\n",
    "\n",
    "  # Set up a Linear + Cosine Scheduler\n",
    "  warmup_scheduler = LinearLR(optimizers[key], start_factor=1e-6 / 3e-4, end_factor=1.0, total_iters=25)\n",
    "  cosine_scheduler = CosineAnnealingLR(optimizers[key], T_max=epochs, eta_min=1e-6)\n",
    "  schedulers[key] = SequentialLR(optimizers[key], schedulers=[warmup_scheduler, cosine_scheduler], milestones=[25])\n",
    "\n",
    "\n",
    "criterion = nn.L1Loss(reduction=\"mean\") # change to mean reduction \n",
    "\n",
    "train_usae(names=list(models.keys()),\n",
    "           models=SAEs,\n",
    "           dataloader=activations_dataloader,\n",
    "           criterion=criterion,\n",
    "           nb_epochs=epochs,\n",
    "           optimizers=optimizers,\n",
    "           schedulers=schedulers,\n",
    "           device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69b4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dicts = {name: model.state_dict() for name, model in SAEs.items()}\n",
    "torch.save(model_state_dicts, \"./models/USAE_ViT_SigLIP_20epoch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e63e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the funny part, we have access to 4 functions that allow us to inspect the concepts,\n",
    "# let use them to understand a bit more the top 3 concepts !\n",
    "\n",
    "\n",
    "## Create a tensor to save a list of top activations\n",
    "topk = int(0.08 * 768 * 7) \n",
    "selected_concepts = torch.zeros(topk+1)\n",
    "activations = next(iter(activations_dataloader))\n",
    "\n",
    "for i, (key, model) in enumerate(models.items()):\n",
    "  sae = SAEs[key]\n",
    "  Activations = activations[f'activations_{key}'].to(device)\n",
    "  with torch.no_grad():\n",
    "    pre_codes, codes = sae.encode(Activations.squeeze())\n",
    "    \n",
    "    codes = rearrange(codes, '(n w h) d -> n w h d', w=16, h=16)\n",
    "    \n",
    "    codes_flat = codes.abs().sum(dim=(1, 2))        \n",
    "    concept_strength = codes_flat.sum(dim=0)        \n",
    "    top_concepts = torch.argsort(concept_strength, descending=True)[:topk].to(device)\n",
    "    selected_concepts[i:i + topk] = top_concepts\n",
    "\n",
    "\n",
    "\n",
    "# Overlay Top 20 for this model\n",
    "for id in selected_concepts:\n",
    "#for concept_id in range(50):\n",
    "  concept_id = int(id.item())\n",
    "  for key, model in models.items():\n",
    "    sae = SAEs[key]\n",
    "    Activations = activations[f'activations_{key}'].to(device)\n",
    "    with torch.no_grad():\n",
    "      pre_codes, codes = sae.encode(Activations.squeeze())\n",
    "\n",
    "    codes = rearrange(codes, '(n w h) d -> n w h d', w=14, h=14)\n",
    "    \n",
    "    save_dir = f\"results/usae_run10_vit_siglip/{key}_concepts\"\n",
    "\n",
    "    overlay_top_heatmaps(activations[f\"images\"].squeeze(), codes, concept_id=concept_id)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"concept_{concept_id}_{key}.png\"\n",
    "    filepath = os.path.join(save_dir, filename)\n",
    "    plt.savefig(filepath, bbox_inches='tight', dpi=300)\n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb42d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
