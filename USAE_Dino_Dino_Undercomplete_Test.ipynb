{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ae5fa7",
   "metadata": {},
   "source": [
    "#### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd86d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from lib.data_handlers import Load_ImageNet100, Load_PACS\n",
    "from overcomplete.models import DinoV2, ViT, ResNet, ViT_Large, SigLIP\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from overcomplete.sae import TopKSAE, train_sae\n",
    "from overcomplete.visualization import (overlay_top_heatmaps, evidence_top_images, zoom_top_images, contour_top_image)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "from lib.universal_trainer import train_usae\n",
    "from lib.activation_generator import Load_activation_dataloader\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
    "from lib.eval import evaluate_models\n",
    "from lib.visualizer import visualize_concept\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a7c042",
   "metadata": {},
   "source": [
    "### Train a USAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998439e",
   "metadata": {},
   "source": [
    "Define Models and Generate Their Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a68d84da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\sproj_ha/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "Using cache found in C:\\Users\\sproj_ha/.cache\\torch\\hub\\facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Dino1\": DinoV2(device=\"cuda\"),\n",
    "    \"Dino2\": DinoV2(device=\"cuda\")\n",
    "}\n",
    "\n",
    "activation_dir = \"activations/ImageNet100_Dino_Dino\"\n",
    "image_loader = Load_ImageNet100(transform=None, batch_size=256, shuffle=True)\n",
    "\n",
    "\n",
    "activations_dataloader = Load_activation_dataloader(\n",
    "    models=models,\n",
    "    image_dataloader=image_loader,\n",
    "    max_seq_len=196,   \n",
    "    save_dir=activation_dir, \n",
    "    generate=False,  \n",
    "    rearrange_string='n t d -> (n t) d'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35fc11e",
   "metadata": {},
   "source": [
    "SAE Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cae4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = 786 * 8\n",
    "epochs = 50\n",
    "lr=3e-4\n",
    "sample = next(iter(activations_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24c5428",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAEs = {}\n",
    "optimizers = {}\n",
    "schedulers = {}\n",
    "\n",
    "for key, model in models.items():\n",
    "\n",
    "    SAEs[key] = TopKSAE(\n",
    "        sample[f\"activations_{key}\"].shape[-1],\n",
    "        nb_concepts=concepts,\n",
    "        top_k=10,\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "    optimizers[key] = torch.optim.Adam(SAEs[key].parameters(), lr=lr)\n",
    "\n",
    "    # Set up a Linear + Cosine Scheduler\n",
    "    warmup_scheduler = LinearLR(\n",
    "        optimizers[key], start_factor=1e-6 / 3e-4, end_factor=1.0, total_iters=25\n",
    "    )\n",
    "    cosine_scheduler = CosineAnnealingLR(optimizers[key], T_max=epochs, eta_min=1e-6)\n",
    "    schedulers[key] = SequentialLR(\n",
    "        optimizers[key],\n",
    "        schedulers=[warmup_scheduler, cosine_scheduler],\n",
    "        milestones=[25],\n",
    "    )\n",
    "\n",
    "criterion = nn.L1Loss(reduction=\"mean\")  # change to mean reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "698beefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   9%|▉         | 48/508 [00:12<01:48,  4.22it/s, loss=1.54]c:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:198: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Epoch 1/50: 100%|██████████| 508/508 [02:06<00:00,  4.02it/s, loss=1.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1] Loss: 747.4242 | Time: 126.28s | Dead Features: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 508/508 [02:02<00:00,  4.15it/s, loss=1.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 2] Loss: 709.8987 | Time: 122.32s | Dead Features: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50:  62%|██████▏   | 313/508 [01:16<00:47,  4.10it/s, loss=1.37]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_usae(\n\u001b[32m      2\u001b[39m     names=\u001b[38;5;28mlist\u001b[39m(models.keys()),\n\u001b[32m      3\u001b[39m     models=SAEs,\n\u001b[32m      4\u001b[39m     dataloader=activations_dataloader,\n\u001b[32m      5\u001b[39m     criterion=criterion,\n\u001b[32m      6\u001b[39m     nb_epochs=epochs,\n\u001b[32m      7\u001b[39m     optimizers=optimizers,\n\u001b[32m      8\u001b[39m     schedulers=schedulers,\n\u001b[32m      9\u001b[39m     device=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     seed=\u001b[32m42\u001b[39m,\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\Desktop\\vision_interp\\lib\\universal_trainer.py:66\u001b[39m, in \u001b[36mtrain_usae\u001b[39m\u001b[34m(names, models, dataloader, criterion, optimizers, schedulers, nb_epochs, clip_grad, device, seed)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# tqdm dataloader\u001b[39;00m\n\u001b[32m     60\u001b[39m progress_bar = tqdm(\n\u001b[32m     61\u001b[39m     \u001b[38;5;28menumerate\u001b[39m(dataloader),\n\u001b[32m     62\u001b[39m     total=\u001b[38;5;28mlen\u001b[39m(dataloader),\n\u001b[32m     63\u001b[39m     desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnb_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     64\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_count, batch \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# Reset Everything\u001b[39;00m\n\u001b[32m     68\u001b[39m     total_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[32m   1182\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[32m   1183\u001b[39m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[32m   1184\u001b[39m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28mself\u001b[39m._next_data()\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\Desktop\\vision_interp\\lib\\activation_generator.py:130\u001b[39m, in \u001b[36mPTFilesDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m    129\u001b[39m     \u001b[38;5;66;03m# Load the dictionary from the .pt file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     data_dict = torch.load(\u001b[38;5;28mself\u001b[39m.file_paths[idx])\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m# Assuming the dictionary contains tensors that can be directly used\u001b[39;00m\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# You might need to modify this part based on your specific data structure\u001b[39;00m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\serialization.py:1516\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1514\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[32m   1515\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1516\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1517\u001b[39m             opened_zipfile,\n\u001b[32m   1518\u001b[39m             map_location,\n\u001b[32m   1519\u001b[39m             _weights_only_unpickler,\n\u001b[32m   1520\u001b[39m             overall_storage=overall_storage,\n\u001b[32m   1521\u001b[39m             **pickle_load_args,\n\u001b[32m   1522\u001b[39m         )\n\u001b[32m   1523\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1524\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\serialization.py:2114\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2112\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   2113\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2114\u001b[39m result = unpickler.load()\n\u001b[32m   2115\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2117\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\_weights_only_unpickler.py:532\u001b[39m, in \u001b[36mUnpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    525\u001b[39m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[32m    526\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) > \u001b[32m0\u001b[39m\n\u001b[32m    527\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m torch.serialization._maybe_decode_ascii(pid[\u001b[32m0\u001b[39m]) != \u001b[33m\"\u001b[39m\u001b[33mstorage\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    528\u001b[39m     ):\n\u001b[32m    529\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[32m    530\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    531\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28mself\u001b[39m.persistent_load(pid))\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[32m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[32m0\u001b[39m], LONG_BINGET[\u001b[32m0\u001b[39m]]:\n\u001b[32m    534\u001b[39m     idx = (read(\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[32m0\u001b[39m] == BINGET[\u001b[32m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[33m\"\u001b[39m\u001b[33m<I\u001b[39m\u001b[33m\"\u001b[39m, read(\u001b[32m4\u001b[39m)))[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\serialization.py:2078\u001b[39m, in \u001b[36m_load.<locals>.persistent_load\u001b[39m\u001b[34m(saved_id)\u001b[39m\n\u001b[32m   2076\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2077\u001b[39m     nbytes = numel * torch._utils._element_size(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2078\u001b[39m     typed_storage = load_tensor(\n\u001b[32m   2079\u001b[39m         dtype, nbytes, key, _maybe_decode_ascii(location)\n\u001b[32m   2080\u001b[39m     )\n\u001b[32m   2082\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\torch\\serialization.py:2031\u001b[39m, in \u001b[36m_load.<locals>.load_tensor\u001b[39m\u001b[34m(dtype, numel, key, location)\u001b[39m\n\u001b[32m   2024\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m storage_offset != zip_file.get_record_offset(name):\n\u001b[32m   2025\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2026\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mThis is a debug assert that was run as the `TORCH_SERIALIZATION_DEBUG` environment \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2027\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvariable was set: Incorrect offset for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstorage_offset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m expected \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2028\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_file.get_record_offset(name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2029\u001b[39m             )\n\u001b[32m   2030\u001b[39m     storage = (\n\u001b[32m-> \u001b[39m\u001b[32m2031\u001b[39m         zip_file.get_storage_from_record(name, numel, torch.UntypedStorage)\n\u001b[32m   2032\u001b[39m         ._typed_storage()\n\u001b[32m   2033\u001b[39m         ._untyped_storage\n\u001b[32m   2034\u001b[39m     )\n\u001b[32m   2035\u001b[39m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[32m   2036\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_usae(\n",
    "    names=list(models.keys()),\n",
    "    models=SAEs,\n",
    "    dataloader=activations_dataloader,\n",
    "    criterion=criterion,\n",
    "    nb_epochs=epochs,\n",
    "    optimizers=optimizers,\n",
    "    schedulers=schedulers,\n",
    "    device=\"cuda\",\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69b4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dicts = {name: model.state_dict() for name, model in SAEs.items()}\n",
    "torch.save(model_state_dicts, \"./models/USAE_Dino_Dino_undercomplete_50epoch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the funny part, we have access to 4 functions that allow us to inspect the concepts,\n",
    "# let use them to understand a bit more the top 3 concepts !\n",
    "\n",
    "\n",
    "## Create a tensor to save a list of top activations\n",
    "topk = int(0.08 * 500 * 7) \n",
    "selected_concepts = torch.zeros(topk+1)\n",
    "activations = next(iter(activations_dataloader))\n",
    "\n",
    "for i, (key, model) in enumerate(models.items()):\n",
    "  sae = SAEs[key]\n",
    "  Activations = activations[f'activations_{key}'].to(device)\n",
    "  with torch.no_grad():\n",
    "    pre_codes, codes = sae.encode(Activations.squeeze())\n",
    "    \n",
    "    codes = rearrange(codes, '(n w h) d -> n w h d', w=16, h=16)\n",
    "    \n",
    "    codes_flat = codes.abs().sum(dim=(1, 2))        \n",
    "    concept_strength = codes_flat.sum(dim=0)        \n",
    "    top_concepts = torch.argsort(concept_strength, descending=True)[:topk].to(device)\n",
    "    selected_concepts[i:i + topk] = top_concepts\n",
    "\n",
    "\n",
    "\n",
    "# Overlay Top 20 for this model\n",
    "for id in selected_concepts:\n",
    "#for concept_id in range(50):\n",
    "  concept_id = int(id.item())\n",
    "  for key, model in models.items():\n",
    "    sae = SAEs[key]\n",
    "    Activations = activations[f'activations_{key}'].to(device)\n",
    "    with torch.no_grad():\n",
    "      pre_codes, codes = sae.encode(Activations.squeeze())\n",
    "\n",
    "    codes = rearrange(codes, '(n w h) d -> n w h d', w=14, h=14)\n",
    "    \n",
    "    save_dir = f\"results/usae_run10_vit_siglip/{key}_concepts\"\n",
    "\n",
    "    overlay_top_heatmaps(activations[f\"images\"].squeeze(), codes, concept_id=concept_id)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"concept_{concept_id}_{key}.png\"\n",
    "    filepath = os.path.join(save_dir, filename)\n",
    "    plt.savefig(filepath, bbox_inches='tight', dpi=300)\n",
    "    plt.close()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
