{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ae5fa7",
   "metadata": {},
   "source": [
    "#### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd86d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data_handlers import Load_ImageNet100\n",
    "from overcomplete.models import DinoV2, ViT, ResNet\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from overcomplete.sae import TopKSAE, train_sae\n",
    "from overcomplete.visualization import (overlay_top_heatmaps, evidence_top_images, zoom_top_images, contour_top_image)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70925b5",
   "metadata": {},
   "source": [
    "## ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c996d0",
   "metadata": {},
   "source": [
    "#### Train SAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb76ac1",
   "metadata": {},
   "source": [
    "Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a68d84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(device=\"cuda\")\n",
    "concepts = 384\n",
    "epochs = 30\n",
    "save_dir = \"results/ViT_ImageNet100\"\n",
    "dataloader = Load_ImageNet100(transform=model.preprocess, batch_size=2000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35fc11e",
   "metadata": {},
   "source": [
    "Execute Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b96e0f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Activation Shape:  torch.Size([2000, 196, 768])\n",
      "Rearranged Activation Shape:  torch.Size([392000, 768])\n"
     ]
    }
   ],
   "source": [
    "for image, _ in dataloader:\n",
    "    image = image.to(device)\n",
    "    Activations = model.forward_features(image)\n",
    "    print(\"Raw Activation Shape: \", Activations.shape)\n",
    "    Activations = rearrange(Activations, 'n t d -> (n t) d')\n",
    "    print(\"Rearranged Activation Shape: \", Activations.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "698beefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/30], Loss: 2.1239, R2: 0.4644, L0: 3.0000, Dead Features: 0.0%, Time: 1.4676 seconds\n",
      "Epoch[2/30], Loss: 1.6053, R2: 0.5952, L0: 3.0000, Dead Features: 48.2%, Time: 1.5791 seconds\n",
      "Epoch[3/30], Loss: 1.5564, R2: 0.6075, L0: 3.0000, Dead Features: 37.0%, Time: 1.4667 seconds\n",
      "Epoch[4/30], Loss: 1.5343, R2: 0.6131, L0: 3.0000, Dead Features: 54.9%, Time: 1.4838 seconds\n",
      "Epoch[5/30], Loss: 1.5231, R2: 0.6159, L0: 3.0000, Dead Features: 50.0%, Time: 1.4987 seconds\n",
      "Epoch[6/30], Loss: 1.5171, R2: 0.6175, L0: 3.0000, Dead Features: 54.4%, Time: 1.6841 seconds\n",
      "Epoch[7/30], Loss: 1.5113, R2: 0.6189, L0: 3.0000, Dead Features: 56.0%, Time: 1.7773 seconds\n",
      "Epoch[8/30], Loss: 1.5066, R2: 0.6201, L0: 3.0000, Dead Features: 57.0%, Time: 1.7212 seconds\n",
      "Epoch[9/30], Loss: 1.4991, R2: 0.6220, L0: 3.0000, Dead Features: 64.6%, Time: 1.8111 seconds\n",
      "Epoch[10/30], Loss: 1.4912, R2: 0.6240, L0: 3.0000, Dead Features: 64.1%, Time: 1.7570 seconds\n",
      "Epoch[11/30], Loss: 1.4882, R2: 0.6247, L0: 3.0000, Dead Features: 65.1%, Time: 1.8370 seconds\n",
      "Epoch[12/30], Loss: 1.4860, R2: 0.6253, L0: 3.0000, Dead Features: 69.5%, Time: 1.7767 seconds\n",
      "Epoch[13/30], Loss: 1.4847, R2: 0.6256, L0: 3.0000, Dead Features: 70.6%, Time: 1.7116 seconds\n",
      "Epoch[14/30], Loss: 1.4837, R2: 0.6259, L0: 3.0000, Dead Features: 70.6%, Time: 1.6895 seconds\n",
      "Epoch[15/30], Loss: 1.4813, R2: 0.6265, L0: 3.0000, Dead Features: 71.6%, Time: 1.7756 seconds\n",
      "Epoch[16/30], Loss: 1.4791, R2: 0.6270, L0: 3.0000, Dead Features: 70.3%, Time: 1.7441 seconds\n",
      "Epoch[17/30], Loss: 1.4783, R2: 0.6272, L0: 3.0000, Dead Features: 70.6%, Time: 1.7136 seconds\n",
      "Epoch[18/30], Loss: 1.4779, R2: 0.6274, L0: 3.0000, Dead Features: 71.4%, Time: 2.5090 seconds\n",
      "Epoch[19/30], Loss: 1.4776, R2: 0.6274, L0: 3.0000, Dead Features: 71.4%, Time: 4.2159 seconds\n",
      "Epoch[20/30], Loss: 1.4772, R2: 0.6275, L0: 3.0000, Dead Features: 70.8%, Time: 3.6420 seconds\n",
      "Epoch[21/30], Loss: 1.4765, R2: 0.6277, L0: 3.0000, Dead Features: 71.9%, Time: 3.7318 seconds\n",
      "Epoch[22/30], Loss: 1.4762, R2: 0.6278, L0: 3.0000, Dead Features: 70.6%, Time: 1.7742 seconds\n",
      "Epoch[23/30], Loss: 1.4757, R2: 0.6279, L0: 3.0000, Dead Features: 70.6%, Time: 1.7458 seconds\n",
      "Epoch[24/30], Loss: 1.4744, R2: 0.6282, L0: 3.0000, Dead Features: 69.3%, Time: 1.7146 seconds\n",
      "Epoch[25/30], Loss: 1.4733, R2: 0.6285, L0: 3.0000, Dead Features: 71.6%, Time: 1.7500 seconds\n",
      "Epoch[26/30], Loss: 1.4729, R2: 0.6286, L0: 3.0000, Dead Features: 70.8%, Time: 1.7333 seconds\n",
      "Epoch[27/30], Loss: 1.4727, R2: 0.6287, L0: 3.0000, Dead Features: 71.1%, Time: 1.7000 seconds\n",
      "Epoch[28/30], Loss: 1.4725, R2: 0.6287, L0: 3.0000, Dead Features: 71.6%, Time: 1.7167 seconds\n",
      "Epoch[29/30], Loss: 1.4723, R2: 0.6287, L0: 3.0000, Dead Features: 71.4%, Time: 1.7360 seconds\n",
      "Epoch[30/30], Loss: 1.4722, R2: 0.6288, L0: 3.0000, Dead Features: 71.9%, Time: 1.7476 seconds\n"
     ]
    }
   ],
   "source": [
    "sae = TopKSAE(Activations.shape[-1], nb_concepts=concepts, top_k=3, device='cuda')\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(TensorDataset(Activations), batch_size=1024, shuffle=True)\n",
    "optimizer = torch.optim.Adam(sae.parameters(), lr=5e-4)\n",
    "\n",
    "def criterion(x, x_hat, pre_codes, codes, dictionary):\n",
    "  mse = (x - x_hat).square().mean()\n",
    "  return mse\n",
    "\n",
    "logs = train_sae(sae, dataloader, criterion, optimizer, nb_epochs=epochs, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f35e63e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Code Shape:  torch.Size([392000, 384])\n",
      "Rearranged Code Shape:  torch.Size([2000, 14, 14, 384])\n"
     ]
    }
   ],
   "source": [
    "# now the funny part, we have access to 4 functions that allow us to inspect the concepts,\n",
    "# let use them to understand a bit more the top 3 concepts !\n",
    "\n",
    "sae = sae.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  pre_codes, codes = sae.encode(Activations)\n",
    "\n",
    "\n",
    "print(\"Raw Code Shape: \", codes.shape)\n",
    "codes = rearrange(codes, '(n w h) d -> n w h d', w=14, h=14)\n",
    "print(\"Rearranged Code Shape: \", codes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "806b60de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-108 Concepts by L1 Norm\n",
      "Concept 234\n",
      "Concept 150\n",
      "Concept 59\n",
      "Concept 110\n",
      "Concept 127\n",
      "Concept 365\n",
      "Concept 13\n",
      "Concept 78\n",
      "Concept 254\n",
      "Concept 8\n",
      "Concept 354\n",
      "Concept 275\n",
      "Concept 45\n",
      "Concept 151\n",
      "Concept 293\n",
      "Concept 158\n",
      "Concept 20\n",
      "Concept 195\n",
      "Concept 170\n",
      "Concept 89\n",
      "Concept 72\n",
      "Concept 217\n",
      "Concept 277\n",
      "Concept 373\n",
      "Concept 209\n",
      "Concept 192\n",
      "Concept 169\n",
      "Concept 79\n",
      "Concept 153\n",
      "Concept 270\n",
      "Concept 219\n",
      "Concept 320\n",
      "Concept 65\n",
      "Concept 19\n",
      "Concept 290\n",
      "Concept 274\n",
      "Concept 172\n",
      "Concept 5\n",
      "Concept 96\n",
      "Concept 210\n",
      "Concept 244\n",
      "Concept 358\n",
      "Concept 379\n",
      "Concept 301\n",
      "Concept 36\n",
      "Concept 61\n",
      "Concept 164\n",
      "Concept 50\n",
      "Concept 104\n",
      "Concept 376\n",
      "Concept 356\n",
      "Concept 179\n",
      "Concept 364\n",
      "Concept 327\n",
      "Concept 68\n",
      "Concept 264\n",
      "Concept 93\n",
      "Concept 49\n",
      "Concept 207\n",
      "Concept 242\n",
      "Concept 12\n",
      "Concept 310\n",
      "Concept 269\n",
      "Concept 4\n",
      "Concept 148\n",
      "Concept 218\n",
      "Concept 157\n",
      "Concept 258\n",
      "Concept 268\n",
      "Concept 241\n",
      "Concept 40\n",
      "Concept 294\n",
      "Concept 198\n",
      "Concept 44\n",
      "Concept 307\n",
      "Concept 149\n",
      "Concept 42\n",
      "Concept 58\n",
      "Concept 90\n",
      "Concept 299\n",
      "Concept 176\n",
      "Concept 288\n",
      "Concept 206\n",
      "Concept 278\n",
      "Concept 138\n",
      "Concept 248\n",
      "Concept 345\n",
      "Concept 147\n",
      "Concept 116\n",
      "Concept 201\n",
      "Concept 253\n",
      "Concept 355\n",
      "Concept 135\n",
      "Concept 92\n",
      "Concept 63\n",
      "Concept 223\n",
      "Concept 141\n",
      "Concept 259\n",
      "Concept 160\n",
      "Concept 221\n",
      "Concept 37\n",
      "Concept 366\n",
      "Concept 296\n",
      "Concept 232\n",
      "Concept 0\n",
      "Concept 1\n",
      "Concept 2\n",
      "Concept 3\n"
     ]
    }
   ],
   "source": [
    "# Compute per-concept L1 norm across all spatial positions and batch\n",
    "codes_flat = codes.abs().sum(dim=(1, 2))        # (32, D)\n",
    "concept_strength = codes_flat.sum(dim=0)        # (D,)\n",
    "\n",
    "topk = int((1 - logs['dead_features'][-1]) * concepts)\n",
    "top_concepts = torch.argsort(concept_strength, descending=True)[:topk].to(device)\n",
    "\n",
    "print(f\"Top-{topk} Concepts by L1 Norm\")\n",
    "\n",
    "# first, lets use the simple overlay to get a broad sense of what's going on\n",
    "for concept_id in top_concepts:\n",
    "  print('Concept', concept_id.item())\n",
    "  overlay_top_heatmaps(image, codes, concept_id=concept_id.item())\n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "  filename = f\"concept_{concept_id.item()}.png\"\n",
    "  filepath = os.path.join(save_dir, filename)\n",
    "  plt.savefig(filepath, bbox_inches='tight', dpi=300)\n",
    "  plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79650a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
