{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ae5fa7",
   "metadata": {},
   "source": [
    "#### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd86d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lib.data_handlers import Load_ImageNet100\n",
    "from overcomplete.models import DinoV2, ViT, ResNet\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from overcomplete.sae import TopKSAE, train_sae\n",
    "from overcomplete.visualization import (overlay_top_heatmaps, evidence_top_images, zoom_top_images, contour_top_image)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70925b5",
   "metadata": {},
   "source": [
    "## ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c996d0",
   "metadata": {},
   "source": [
    "#### Train SAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb76ac1",
   "metadata": {},
   "source": [
    "Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68d84da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sproj_ha\\miniconda3\\envs\\interpretability\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "model = ViT(device=\"cuda\")\n",
    "concepts = 786 * 8\n",
    "epochs = 50\n",
    "save_dir = \"results/ViT_ImageNet100\"\n",
    "dataloader = Load_ImageNet100(transform=model.preprocess, batch_size=2000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35fc11e",
   "metadata": {},
   "source": [
    "Execute Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b96e0f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Activation Shape:  torch.Size([2000, 196, 768])\n",
      "Rearranged Activation Shape:  torch.Size([392000, 768])\n"
     ]
    }
   ],
   "source": [
    "for image, _ in dataloader:\n",
    "    image = image.to(device)\n",
    "    Activations = model.forward_features(image)\n",
    "    print(\"Raw Activation Shape: \", Activations.shape)\n",
    "    Activations = rearrange(Activations, 'n t d -> (n t) d')\n",
    "    print(\"Rearranged Activation Shape: \", Activations.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698beefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = TopKSAE(Activations.shape[-1], nb_concepts=concepts, top_k=3, device='cuda')\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(TensorDataset(Activations), batch_size=1024, shuffle=True)\n",
    "optimizer = torch.optim.Adam(sae.parameters(), lr=5e-4)\n",
    "\n",
    "def criterion(x, x_hat, pre_codes, codes, dictionary):\n",
    "  mse = (x - x_hat).square().mean()\n",
    "  return mse\n",
    "\n",
    "logs = train_sae(sae, dataloader, criterion, optimizer, nb_epochs=epochs, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e63e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the funny part, we have access to 4 functions that allow us to inspect the concepts,\n",
    "# let use them to understand a bit more the top 3 concepts !\n",
    "\n",
    "sae = sae.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  pre_codes, codes = sae.encode(Activations)\n",
    "\n",
    "print(\"Raw Code Shape: \", codes.shape)\n",
    "codes = rearrange(codes, '(n w h) d -> n w h d', w=14, h=14)\n",
    "print(\"Rearranged Code Shape: \", codes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-concept L1 norm across all spatial positions and batch\n",
    "codes_flat = codes.abs().sum(dim=(1, 2))        # (32, D)\n",
    "concept_strength = codes_flat.sum(dim=0)        # (D,)\n",
    "\n",
    "topk = int((1 - logs['dead_features'][-1]) * concepts)\n",
    "top_concepts = torch.argsort(concept_strength, descending=True)[:topk].to(device)\n",
    "\n",
    "print(f\"Top-{topk} Concepts by L1 Norm\")\n",
    "\n",
    "# first, lets use the simple overlay to get a broad sense of what's going on\n",
    "for concept_id in top_concepts:\n",
    "  print('Concept', concept_id.item())\n",
    "  overlay_top_heatmaps(image, codes, concept_id=concept_id.item())\n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "  filename = f\"concept_{concept_id.item()}.png\"\n",
    "  filepath = os.path.join(save_dir, filename)\n",
    "  plt.savefig(filepath, bbox_inches='tight', dpi=300)\n",
    "  plt.close()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
